\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Section A}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Dataset A: Exploration, Dimensionality Reduction and Clustering}{2}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Density plots for the first 20 features of Dataset A.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:Q1a_First20Features}{{1}{2}{Density plots for the first 20 features of Dataset A}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Scatter plot of the first 2 principal components of Dataset A, coloured by label.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:Q1b_PCA}{{2}{3}{Scatter plot of the first 2 principal components of Dataset A, coloured by label}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Proportion of data points assigned to each cluster for each model where Pred1 and Pred2 are the two models with default parameters.}}{3}{table.1}\protected@file@percent }
\newlabel{tab:Q1c_contingency}{{1}{3}{Proportion of data points assigned to each cluster for each model where Pred1 and Pred2 are the two models with default parameters}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Proportion of data points assigned to each cluster for each model where Pred1 and Pred2 are the two models with three clusters.}}{4}{table.2}\protected@file@percent }
\newlabel{tab:Q1d_contingency}{{2}{4}{Proportion of data points assigned to each cluster for each model where Pred1 and Pred2 are the two models with three clusters}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Scatter plot of the first 2 principal components of Dataset A, coloured by cluster.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:Q1e_PCA}{{3}{4}{Scatter plot of the first 2 principal components of Dataset A, coloured by cluster}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Scatter plot of the first 2 principal components of Dataset A, coloured by cluster.}}{5}{figure.4}\protected@file@percent }
\newlabel{fig:Q1e_PCA_KMeans}{{4}{5}{Scatter plot of the first 2 principal components of Dataset A, coloured by cluster}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Dataset B: Missing Labels and Duplicated Observations}{5}{subsection.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Number of observations and proportion for each label in Dataset B.}}{5}{table.3}\protected@file@percent }
\newlabel{tab:Q2a_label_counts}{{3}{5}{Number of observations and proportion for each label in Dataset B}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Number of observations and proportion for each label in Dataset B before and after imputing missing labels. Missing values are ignored in the calculation of proportions before to allow better comparison.}}{6}{table.4}\protected@file@percent }
\newlabel{tab:Q2d_label_counts}{{4}{6}{Number of observations and proportion for each label in Dataset B before and after imputing missing labels. Missing values are ignored in the calculation of proportions before to allow better comparison}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Dataset C: Missing Data and Outliers}{7}{subsection.1.3}\protected@file@percent }
\newlabel{subsec:Q3}{{1.3}{7}{Dataset C: Missing Data and Outliers}{subsection.1.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results of 3-fold cross-validation for several regression models. The scoring used was the negative root mean squared error.}}{7}{table.5}\protected@file@percent }
\newlabel{tab:Q3c_CV}{{5}{7}{Results of 3-fold cross-validation for several regression models. The scoring used was the negative root mean squared error}{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of the original and imputed distributions.}}{8}{figure.5}\protected@file@percent }
\newlabel{fig:Q3c_Imputed_Distribution}{{5}{8}{Comparison of the original and imputed distributions}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualisation of outliers in Dataset C where black means the value is not an outlier and white values indicate an outlier.}}{9}{figure.6}\protected@file@percent }
\newlabel{fig:Q3d_outliers}{{6}{9}{Visualisation of outliers in Dataset C where black means the value is not an outlier and white values indicate an outlier}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Distribution of values in the top five features with the most outliers from the original dataset.}}{10}{figure.7}\protected@file@percent }
\newlabel{fig:Q3e_outliers_original}{{7}{10}{Distribution of values in the top five features with the most outliers from the original dataset}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Distribution of values from Fea366 from the original and outlier-corrected datasets.}}{10}{figure.8}\protected@file@percent }
\newlabel{fig:Q3e_outliers_corrected}{{8}{10}{Distribution of values from Fea366 from the original and outlier-corrected datasets}{figure.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Section B}{10}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Baseline Dataset: Supervised Learning and Random Forests}{10}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Visualisation of outliers in the baseline dataset where black means the value is not an outlier and white values indicate an outlier.}}{11}{figure.9}\protected@file@percent }
\newlabel{fig:Q4b_outliers}{{9}{11}{Visualisation of outliers in the baseline dataset where black means the value is not an outlier and white values indicate an outlier}{figure.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Evaluation metrics for the Random Forest Classifier.}}{12}{table.6}\protected@file@percent }
\newlabel{tab:Q4c_metrics}{{6}{12}{Evaluation metrics for the Random Forest Classifier}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Confusion matrix for the Random Forest Classifier.}}{12}{table.7}\protected@file@percent }
\newlabel{tab:Q4c_confusion_matrix}{{7}{12}{Confusion matrix for the Random Forest Classifier}{table.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Confusion matrix for the Random Forest Classifier with 1,000 features.}}{12}{table.8}\protected@file@percent }
\newlabel{tab:Q4e_confusion_matrix_original}{{8}{12}{Confusion matrix for the Random Forest Classifier with 1,000 features}{table.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Validation curve for the Random Forest Classifier with respect to the number of trees.}}{13}{figure.10}\protected@file@percent }
\newlabel{fig:Q4d_validation_curve}{{10}{13}{Validation curve for the Random Forest Classifier with respect to the number of trees}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Confusion matrix for the Random Forest Classifier with 268 features.}}{13}{table.9}\protected@file@percent }
\newlabel{tab:Q4e_confusion_matrix_retrained}{{9}{13}{Confusion matrix for the Random Forest Classifier with 268 features}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Evaluation metrics for the Support Vector Classifier with default parameters.}}{13}{table.10}\protected@file@percent }
\newlabel{tab:Q4f_metrics}{{10}{13}{Evaluation metrics for the Support Vector Classifier with default parameters}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Confusion matrix for the Support Vector Classifier.}}{14}{table.11}\protected@file@percent }
\newlabel{tab:Q4f_confusion_matrix}{{11}{14}{Confusion matrix for the Support Vector Classifier}{table.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Confusion matrix for the Support Vector Classifier with 1,000 features and default parameters.}}{14}{table.12}\protected@file@percent }
\newlabel{tab:Q4f_confusion_matrix_original}{{12}{14}{Confusion matrix for the Support Vector Classifier with 1,000 features and default parameters}{table.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Confusion matrix for the Support Vector Classifier with 208 features and default parameters.}}{14}{table.13}\protected@file@percent }
\newlabel{tab:Q4f_confusion_matrix_retrained}{{13}{14}{Confusion matrix for the Support Vector Classifier with 208 features and default parameters}{table.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Baseline Dataset: Unsupervised Learning - Clustering}{15}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Silhouette scores for $k$-means clustering.}}{15}{figure.11}\protected@file@percent }
\newlabel{fig:Q5a_silhouette_scores}{{11}{15}{Silhouette scores for $k$-means clustering}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Silhouette scores for agglomerative clustering.}}{16}{figure.12}\protected@file@percent }
\newlabel{fig:Q5a_silhouette_scores_agg}{{12}{16}{Silhouette scores for agglomerative clustering}{figure.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Contingency table for $k$-means and agglomerative clustering.}}{16}{table.14}\protected@file@percent }
\newlabel{tab:Q5a_contingency_table}{{14}{16}{Contingency table for $k$-means and agglomerative clustering}{table.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Contingency table for $k$-means clustering with the complete and subset of the dataset.}}{16}{table.15}\protected@file@percent }
\newlabel{tab:Q5b_kmeans_contingency_table}{{15}{16}{Contingency table for $k$-means clustering with the complete and subset of the dataset}{table.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Contingency table for agglomerative clustering with the complete and subset of the dataset.}}{17}{table.16}\protected@file@percent }
\newlabel{tab:Q5b_agg_contingency_table}{{16}{17}{Contingency table for agglomerative clustering with the complete and subset of the dataset}{table.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Clusters coloured by cluster membership for $k$-means and agglomerative clustering models.}}{17}{figure.13}\protected@file@percent }
\newlabel{fig:Q5c_clusters}{{13}{17}{Clusters coloured by cluster membership for $k$-means and agglomerative clustering models}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Clusters coloured by the most discriminative feature for $k$-means and agglomerative clustering models.}}{18}{figure.14}\protected@file@percent }
\newlabel{fig:Q5c_top_feature}{{14}{18}{Clusters coloured by the most discriminative feature for $k$-means and agglomerative clustering models}{figure.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Clusters coloured by the next most discriminative feature for $k$-means and agglomerative clustering models.}}{18}{figure.15}\protected@file@percent }
\newlabel{fig:Q5c_next_feature}{{15}{18}{Clusters coloured by the next most discriminative feature for $k$-means and agglomerative clustering models}{figure.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Appendix}{18}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}README}{18}{subsection.3.1}\protected@file@percent }
\gdef \@abspage@last{19}
